{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20e10f12",
   "metadata": {},
   "source": [
    "PROJECT 1\n",
    "\n",
    "Description:  You should consider yourself as a\n",
    "new employee in a company who has just been given a data. Your job is to make a useful description of the data set for your co-workers and make some basic plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb9b373",
   "metadata": {},
   "source": [
    "Import relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b87839b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# Plotting style\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_theme(font_scale=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef0a807",
   "metadata": {},
   "source": [
    "# 1.  Description of you dataset\n",
    "\n",
    "• Explain the overall problem of interest and the associated data.  \n",
    "\n",
    "• Provide a reference to where you obtained the data.  \n",
    "\n",
    "• Summarize previous analysis of the data. (i.e. go through one or two of the original source papers and read what they did to the data and summarize their results).  \n",
    "\n",
    "\n",
    "• You will be asked to apply (1) classification and (2) regression on your data in the next report. For now, we want you to consider how this should be done. Therefore:  \n",
    "\n",
    "– Explain, in the context of your problem of interest, what you hope to accomplish/learn from the data using these techniques?  \n",
    "\n",
    "– Explain which attribute you wish to predict in the regression based on which other attributes?  \n",
    "\n",
    "– Which class label will you predict based on which other attributes in the classification task?  \n",
    "\n",
    "– Explain if you need to transform individual attribues in order to carry out these tasks (e.g. centering, standardization, discretization, log transform, etc.) and how you plan to do this.  \n",
    "\n",
    "One of these tasks is likely more relevant than the rest and will be denoted the main machine learning aim in the following.\n",
    "The purpose of the following questions, which asks you to describe/visualize the data, is to allow you to reflect on the feasibility of the main machine learning aim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9872f3ce",
   "metadata": {},
   "source": [
    "Load relevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc5a3629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    AAT_ECOLI  0.49  0.29  0.48  0.50  0.56  0.24  0.35  cp\n",
      "0  ACEA_ECOLI  0.07  0.40  0.48   0.5  0.54  0.35  0.44  cp\n",
      "1  ACEK_ECOLI  0.56  0.40  0.48   0.5  0.49  0.37  0.46  cp\n",
      "2  ACKA_ECOLI  0.59  0.49  0.48   0.5  0.52  0.45  0.36  cp\n",
      "3   ADI_ECOLI  0.23  0.32  0.48   0.5  0.55  0.25  0.35  cp\n",
      "4  ALKH_ECOLI  0.67  0.39  0.48   0.5  0.36  0.38  0.46  cp\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "\n",
    "df = pd.read_fwf(\"data/ecoli.data\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a396809f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a local .data file (tries common delimiters)\n",
    "from pathlib import Path\n",
    "\n",
    "# Example: change to your file path\n",
    "local_path = Path('data/ecoli.data')\n",
    "assert local_path.exists(), f'File not found: {local_path}'\n",
    "\n",
    "# Try common separators\n",
    "separators = [r'\\s+', ',', '\\t', ';', '|']\n",
    "loaded = False\n",
    "for sep in separators:\n",
    "    try:\n",
    "        temp_df = pd.read_csv(local_path, sep=sep, header=None, engine='python')\n",
    "        # Heuristic: consider it valid if we get more than 1 column\n",
    "        if temp_df.shape[1] > 1:\n",
    "            df = temp_df\n",
    "            print(f'Loaded with sep={sep!r}, shape={df.shape}')\n",
    "            loaded = True\n",
    "            break\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "if not loaded:\n",
    "    # Fallback to default parsing\n",
    "    df = pd.read_csv(local_path, header=None)\n",
    "    print('Loaded with default parser (no explicit sep). Shape:', df.shape)\n",
    "\n",
    "# Optional: assign column names when known (example for Ecoli dataset)\n",
    "if df.shape[1] == 9:\n",
    "    df.columns = [\n",
    "        'sequence_name', 'mcg', 'gvh', 'lip', 'chg', 'aac', 'alm1', 'alm2', 'class'\n",
    "    ]\n",
    "    print('Assigned Ecoli column names.')\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e511c0",
   "metadata": {},
   "source": [
    "Print information about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3359dbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert fixed-width (.fwf) to CSV\n",
    "from pathlib import Path\n",
    "\n",
    "# Change this if your file is elsewhere\n",
    "fwf_path = Path('data/ecoli.data')\n",
    "assert fwf_path.exists(), f'File not found: {fwf_path}'\n",
    "\n",
    "# Read as fixed-width (let pandas infer column breaks)\n",
    "df = pd.read_fwf(fwf_path, header=None, infer_nrows=200)\n",
    "print('FWF loaded shape:', df.shape)\n",
    "\n",
    "# Optional: assign known Ecoli column names if matches expected width\n",
    "if df.shape[1] == 9:\n",
    "    df.columns = [\n",
    "        'sequence_name', 'mcg', 'gvh', 'lip', 'chg', 'aac', 'alm1', 'alm2', 'class'\n",
    "    ]\n",
    "    print('Assigned Ecoli column names.')\n",
    "\n",
    "# Write CSV next to original file\n",
    "csv_path = fwf_path.with_suffix('.csv')\n",
    "df.to_csv(csv_path, index=False)\n",
    "print('Wrote CSV to:', csv_path)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa08375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print information about the data  \n",
    "print(df.info())\n",
    "print(df.head())\n",
    "print(df.describe())\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4662e8",
   "metadata": {},
   "source": [
    "# 2. Detailed explanation of the attributes of the data\n",
    "\n",
    "• Describe if the attributes are discrete/continuous and whether they are nominal/ordinal/interval/ratio.  \n",
    "\n",
    "• Give an account of whether there are data issues (i.e. missing values or corrupted data) and describe them if so and how you will handle them.  \n",
    "\n",
    "• Include relevant summary statistics of the attributes. Reflect on the values.  \n",
    "\n",
    "If your data set contains many similar attributes, you may restrict yourself to describing a few representative features (apply common sense). You can place additional results in the\n",
    "appendix if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a671c2c",
   "metadata": {},
   "source": [
    "Find data issues and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34298a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find data issues (i.e. missing values or corrupted data)\n",
    "print(df.isnull().sum())\n",
    "# Drop rows with missing values\n",
    "df = df.dropna()\n",
    "# Alternatively, you could fill missing values with the mean or median\n",
    "# df = df.fillna(df.mean())\n",
    "# df = df.fillna(df.median())\n",
    "# Encode categorical variables if any\n",
    "label_encoders = {}\n",
    "for column in df.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    df[column] = le.fit_transform(df[column])\n",
    "    label_encoders[column] = le\n",
    "# Split data into attribute matrix and target matrix\n",
    "X = df.drop('target_column', axis=1)  # Replace 'target_column'\n",
    "y = df['target_column']  # Replace 'target_column'\n",
    "# with the actual name of your target column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a14029",
   "metadata": {},
   "source": [
    "Make summary statistics on attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426faa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include summary statistics of the attributes\n",
    "print(X.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6823db23",
   "metadata": {},
   "source": [
    "# 3. Data visualization(s) based on suitable visualization techniques\n",
    "\n",
    "Touch upon the following aspects, use visualizations when it appears sensible. Keep in mind the ACCENT principles and Tufte’s guidelines when you visualize the data.\n",
    "\n",
    "\n",
    "• Are there issues with extreme values or outliers in the data?  \n",
    "\n",
    "• How are the individual attributes distributed (e.g. normally distributed)?  \n",
    "\n",
    "• Are the attributes correlated?  \n",
    "\n",
    "There are three aspects that needs to be addressed when you carry out the PCA analysis for the report: \n",
    "\n",
    "• The principal directions of the considered PCA components. Plot and interpret the components in terms of the attributes.  \n",
    "\n",
    "• The amount of variance explained as a function of the number of PCA components included.  \n",
    "\n",
    "• The data projected onto the considered principal components, e.g. in 2D scatter plots (hint: it may be helpful to color code the points according to the value of the attribute\n",
    "you wish to predict).  \n",
    "\n",
    "Hint: If your attributes have very different scales, it may be helpful to standardized the\n",
    "data prior to the PC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtu02452",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
